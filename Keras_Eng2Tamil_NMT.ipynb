{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Keras_Eng2Tamil_NMT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "DoGA-re5JUUo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tohbenghwee/mldds/blob/master/Keras_Eng2Tamil_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhTfHHVuwdjS",
        "colab_type": "text"
      },
      "source": [
        "#Steps\n",
        "- Load data\n",
        "- Preprocess, tokenize, pad sequences\n",
        "- Design Arch\n",
        "- Fit the model\n",
        "- Evalute \n",
        "- Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V0-fG_duJUPY"
      },
      "source": [
        "### Datasets\n",
        "http://www.manythings.org/anki/  (Download and unzip mar-tam.zip file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LVbPhusKJjdm",
        "colab": {}
      },
      "source": [
        "# !wget http://www.manythings.org/anki/tam-eng.zip\n",
        "# from zipfile import ZipFile\n",
        "# ZipFile('mar-eng.zip').extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVnvISzg2yzI",
        "colab_type": "text"
      },
      "source": [
        "### link to visualize model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiJJWrEV27c9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://lutzroeder.github.io/netron/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiqqazUvyYxy",
        "colab_type": "text"
      },
      "source": [
        "#Import Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b5mfruWKJUPa",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, CuDNNLSTM\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOH1MzNow1Eu",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mzwabd5-JUPh",
        "colab": {}
      },
      "source": [
        "lines= pd.read_csv('tam.txt', names=['eng', 'tam'], sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWFbyrE43I--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lines = lines.sample(n=10000, replace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP5cHsW6w8uP",
        "colab_type": "text"
      },
      "source": [
        "#Preprocess, tokenize, pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jIq4k0aDJUPk",
        "outputId": "f6f6a589-ce0b-4fe0-849f-5e5796c68a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eNi-n4ABKCmg",
        "outputId": "8d1cdf56-edc8-4abd-e331-268381e160e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "lines.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>tam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>Do you know when he will come?</td>\n",
              "      <td>அவன் எப்ப வருவான் என்று உனக்குத் தெரியுமா</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Because he's sick, he can't come.</td>\n",
              "      <td>அவனுக்கு உடல் நிலை சரியில்லாததனால் அவனால் வர இ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Give it to her.</td>\n",
              "      <td>அவளிடம் கொடு</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Beware of the dog!</td>\n",
              "      <td>நாய் ஜாக்கிரதை!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>Tom has been crying all afternoon.</td>\n",
              "      <td>டாம் மதியம் முழுவதும் அழுதுகொண்டேயிருக்கிறான்.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    eng                                                tam\n",
              "159      Do you know when he will come?          அவன் எப்ப வருவான் என்று உனக்குத் தெரியுமா\n",
              "176   Because he's sick, he can't come.  அவனுக்கு உடல் நிலை சரியில்லாததனால் அவனால் வர இ...\n",
              "17                      Give it to her.                                       அவளிடம் கொடு\n",
              "45                   Beware of the dog!                                    நாய் ஜாக்கிரதை!\n",
              "180  Tom has been crying all afternoon.     டாம் மதியம் முழுவதும் அழுதுகொண்டேயிருக்கிறான்."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "urvHaLJSJUPo",
        "colab": {}
      },
      "source": [
        "# Lowercase all characters\n",
        "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
        "lines.tam=lines.tam.apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "669zPSiKJUPr",
        "colab": {}
      },
      "source": [
        "# Remove quotes\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines.tam=lines.tam.apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bF2thFAQJUPv",
        "colab": {}
      },
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines.tam=lines.tam.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAwiMa9FJUP0",
        "colab": {}
      },
      "source": [
        "# Remove all numbers from text\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
        "lines.tam=lines.tam.apply(lambda x: x.translate(remove_digits))\n",
        "# lines.tam = lines.tam.apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HijONF0gJUP4",
        "colab": {}
      },
      "source": [
        "# Remove extra spaces\n",
        "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
        "lines.tam=lines.tam.apply(lambda x: x.strip())\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines.tam=lines.tam.apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "actCgsx8JUP7",
        "colab": {}
      },
      "source": [
        "# Add start and end tokens to target sequences\n",
        "lines.tam = lines.tam.apply(lambda x : 'START_ '+ x + ' _END')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dKpZpk2mJUP_",
        "outputId": "3ce593b9-879f-4274-9724-139a078eea28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "lines.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>tam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>its my fault that the cake was burned i was ta...</td>\n",
              "      <td>START_ என்னுடையத் தவறினால் கேக்கானதுக் கருகிப்...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>im proud of my son</td>\n",
              "      <td>START_ என் மகனைப் பற்றி பெருமைப் படுகிறேன் _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>she got married to him</td>\n",
              "      <td>START_ அவள் அவனுக்கு திருமணம் செய்து வைக்கப் ப...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>dont lie to me</td>\n",
              "      <td>START_ என்னிடம் பொய் சொல்லாதே _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>she went out of the room</td>\n",
              "      <td>START_ அவள் அறையை விட்டு வெளியே சென்றாள் _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>he is still here</td>\n",
              "      <td>START_ அவன் இன்னும் இருக்கிறான் _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>shut up and listen</td>\n",
              "      <td>START_ வாயை மூடி கவனி _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>he got a lot of money</td>\n",
              "      <td>START_ அவனுக்கு நிறைய பணம் கிடைத்தது _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>i cant find it anywhere</td>\n",
              "      <td>START_ இது எங்கே இருக்கு என்று என்னால் கண்டுபி...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>it seems she hates you</td>\n",
              "      <td>START_ அவள் உன்னை வெறுக்கிற மாதிரி தெரிகிறது _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   eng                                                tam\n",
              "196  its my fault that the cake was burned i was ta...  START_ என்னுடையத் தவறினால் கேக்கானதுக் கருகிப்...\n",
              "80                                  im proud of my son    START_ என் மகனைப் பற்றி பெருமைப் படுகிறேன் _END\n",
              "125                             she got married to him  START_ அவள் அவனுக்கு திருமணம் செய்து வைக்கப் ப...\n",
              "25                                      dont lie to me                 START_ என்னிடம் பொய் சொல்லாதே _END\n",
              "144                           she went out of the room      START_ அவள் அறையை விட்டு வெளியே சென்றாள் _END\n",
              "36                                    he is still here               START_ அவன் இன்னும் இருக்கிறான் _END\n",
              "64                                  shut up and listen                         START_ வாயை மூடி கவனி _END\n",
              "105                              he got a lot of money          START_ அவனுக்கு நிறைய பணம் கிடைத்தது _END\n",
              "141                            i cant find it anywhere  START_ இது எங்கே இருக்கு என்று என்னால் கண்டுபி...\n",
              "123                             it seems she hates you  START_ அவள் உன்னை வெறுக்கிற மாதிரி தெரிகிறது _END"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HLCHvVlYJUQJ",
        "colab": {}
      },
      "source": [
        "def get_vocab_set(series):\n",
        "    allwords=set()\n",
        "    for s in series:\n",
        "        for word in s.split():\n",
        "            if word not in allwords:\n",
        "                allwords.add(word)\n",
        "    return allwords\n",
        "\n",
        "# Vocabulary of English\n",
        "all_eng_words=get_vocab_set(lines.eng)\n",
        "# Vocabulary of Tam\n",
        "all_tam_words=get_vocab_set(lines.tam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "20WmvDf8JUQO",
        "colab": {}
      },
      "source": [
        "def get_max_len(series):\n",
        "    lenght_list = [ len(l.split(' ')) for l in series ]\n",
        "    max_length = np.max(lenght_list)\n",
        "    return max_length\n",
        "\n",
        "# Max Length of source sequence\n",
        "max_length_src = get_max_len(lines.eng)\n",
        "# max_length_src\n",
        "\n",
        "# Max Length of target sequence\n",
        "max_length_tar = get_max_len(lines.tam)\n",
        "# max_length_tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBFAH7EDJUQY",
        "outputId": "418ed70b-5a75-4fd4-86bb-c0dfeb20740d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_tam_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_tam_words)\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(374, 537)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eWF4USWwJUQb",
        "outputId": "583573ab-1fd3-4f8f-cef7-2b2977187020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "num_decoder_tokens += 1 # For zero padding\n",
        "num_decoder_tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9p6yRHLMJUQe",
        "colab": {}
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ddl07apLJUQi",
        "colab": {}
      },
      "source": [
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HOu-HfIkJUQn",
        "outputId": "2b899a7f-879f-403d-e235-d9995b96b64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>tam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>come home before six</td>\n",
              "      <td>START_ ஆறு மணிக்கு முன்பு வீட் டிற்கு வா _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>theres no easy way out of here</td>\n",
              "      <td>START_ இங்கிருந்து வெளியே செல்ல சுலபமான வழியில...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>she smiled</td>\n",
              "      <td>START_ அவள் சிரித்தாள் _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>all of them went there</td>\n",
              "      <td>START_ அவர்கள் எல்லோரும் அங்கே சென்றார்கள் _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>friendship requires mutual trust</td>\n",
              "      <td>START_ நட்புக்குத் தேவை பரஸ்பர நம்பிக்கை _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>roll the ball to me</td>\n",
              "      <td>START_ பந்தை என்னிடம் உருட்டி விடு _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>its a piece of cake</td>\n",
              "      <td>START_ இது ஒரு கேக்கின் துண்டு _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>he put the ring on marys finger</td>\n",
              "      <td>START_ அவன் மேரியின் விரலில் மோதிரத்தை அணிவித்...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>she got married to him</td>\n",
              "      <td>START_ அவள் அவனுக்கு திருமணம் செய்து வைக்கப் ப...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>its time to get up</td>\n",
              "      <td>START_ தூக்கத்திலிருந்து எழுவதற்கான நேரம் இது ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  eng                                                tam\n",
              "93               come home before six      START_ ஆறு மணிக்கு முன்பு வீட் டிற்கு வா _END\n",
              "173    theres no easy way out of here  START_ இங்கிருந்து வெளியே செல்ல சுலபமான வழியில...\n",
              "5                          she smiled                        START_ அவள் சிரித்தாள் _END\n",
              "115            all of them went there    START_ அவர்கள் எல்லோரும் அங்கே சென்றார்கள் _END\n",
              "177  friendship requires mutual trust      START_ நட்புக்குத் தேவை பரஸ்பர நம்பிக்கை _END\n",
              "86                roll the ball to me            START_ பந்தை என்னிடம் உருட்டி விடு _END\n",
              "97                its a piece of cake                START_ இது ஒரு கேக்கின் துண்டு _END\n",
              "178   he put the ring on marys finger  START_ அவன் மேரியின் விரலில் மோதிரத்தை அணிவித்...\n",
              "125            she got married to him  START_ அவள் அவனுக்கு திருமணம் செய்து வைக்கப் ப...\n",
              "84                 its time to get up  START_ தூக்கத்திலிருந்து எழுவதற்கான நேரம் இது ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X6k_N1l1JUQq",
        "outputId": "bb52263a-35b6-454d-d5c6-f10abaa693ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Train - Test Split\n",
        "X, y = lines.eng, lines.tam\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9000,), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-K7IxWcoJUQu"
      },
      "source": [
        "#### Save the train and test dataframes for reproducing the results later, as they are shuffled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EMdMVu6TJUQv",
        "colab": {}
      },
      "source": [
        "X_train.to_pickle('X_train_eng2tam.pkl')\n",
        "X_test.to_pickle('X_test_eng2tam.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98OJ24V1JUQ5",
        "colab": {}
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zsk8sHaJJURA"
      },
      "source": [
        "### Encoder - Decoder Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AK7j1Z1nJURC",
        "colab": {}
      },
      "source": [
        "latent_dim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rxp8v_IrJURJ",
        "colab": {}
      },
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uca8f5C8JURO",
        "colab": {}
      },
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DubtXsGYJURY",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_4jEs_o0Dua",
        "colab_type": "code",
        "outputId": "b5c58aa7-c80f-4083-f8dc-a65d49ec3c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, None, 50)     18700       input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, None, 50)     26900       input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   [(None, 50), (None,  20200       embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, None, 50), ( 20200       embedding_8[0][0]                \n",
            "                                                                 lstm_7[0][1]                     \n",
            "                                                                 lstm_7[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, None, 538)    27438       lstm_8[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 113,438\n",
            "Trainable params: 113,438\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hve7L8qv0i3I",
        "colab_type": "code",
        "outputId": "8bd3000a-569b-4fa0-81df-5137d2a78f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "model.save(\"tmp.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_8 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_7/while/Exit_2:0' shape=(?, 50) dtype=float32>, <tf.Tensor 'lstm_7/while/Exit_3:0' shape=(?, 50) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7BugEydxGUf",
        "colab_type": "text"
      },
      "source": [
        "#Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql9pN4JQv_JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TIME TAKEN TO FIT :  1 loop, best of 3: 31.7 s per loop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MkLto3bnJURd",
        "colab": {}
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128 #128\n",
        "epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlCzaf9ChD-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # print(batch_size)\n",
        "# out = generate_batch(X_train, y_train, batch_size = batch_size)\n",
        "# for some_X, some_Y in out:\n",
        "#     print(some_X[0].shape)\n",
        "#     print(some_X[1].shape)\n",
        "#     print(some_Y[0].shape)\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "64uSOUVKJURf",
        "outputId": "e76d1db5-0b5c-412e-88a9-894e9235ef27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%timeit\n",
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs)\n",
        "#                     validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "#                     validation_steps = val_samples//batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "70/70 [==============================] - 4s 64ms/step - loss: 1.7510 - acc: 0.7481\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 1.3718 - acc: 0.8418\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 1.0584 - acc: 0.9073\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.8142 - acc: 0.9387\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 4s 61ms/step - loss: 0.6297 - acc: 0.9655\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.4930 - acc: 0.9798\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.3929 - acc: 0.9855\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.3185 - acc: 0.9893\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.2628 - acc: 0.9937\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.2191 - acc: 0.9959\n",
            "Epoch 1/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.1847 - acc: 0.9973\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.1585 - acc: 0.9973\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.1372 - acc: 0.9982\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.1194 - acc: 0.9988\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.1052 - acc: 0.9994\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0931 - acc: 0.9996\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0832 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0744 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0670 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 4s 64ms/step - loss: 0.0607 - acc: 1.0000\n",
            "Epoch 1/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0550 - acc: 1.0000\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0503 - acc: 1.0000\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0461 - acc: 1.0000\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0422 - acc: 1.0000\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0390 - acc: 1.0000\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0359 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0333 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0309 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0288 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 4s 61ms/step - loss: 0.0268 - acc: 1.0000\n",
            "Epoch 1/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0250 - acc: 1.0000\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0234 - acc: 1.0000\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0220 - acc: 1.0000\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0206 - acc: 1.0000\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0194 - acc: 1.0000\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 4s 64ms/step - loss: 0.0182 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0172 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0162 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 4s 63ms/step - loss: 0.0153 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 4s 62ms/step - loss: 0.0144 - acc: 1.0000\n",
            "1 loop, best of 3: 43.7 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7VIDbOf1VB5",
        "colab_type": "code",
        "outputId": "d78ec8c6-70d0-4aad-cc4a-30bd0b0f7d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# %%timeit\n",
        "model.evaluate_generator(generate_batch(X_train, y_train),steps = 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.014143630241354307, 1.0000000198682149]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9oWplu118RJ",
        "colab_type": "code",
        "outputId": "981f2317-69fa-4fbe-fdcb-9709f4d64135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.evaluate_generator(generate_batch(X_test, y_test),steps = 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.014131749980151653, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C_YB0h_RJURi"
      },
      "source": [
        "### Always remember to save the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "is1YtldKJURj",
        "colab": {}
      },
      "source": [
        "model.save_weights('nmt_eng2tam_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C9-qT2YxJURn"
      },
      "source": [
        "### Load the weights, if you close the application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8v9S2eHjJURp",
        "colab": {}
      },
      "source": [
        "model.load_weights('nmt_eng2tam_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hfXHLkNlJURu"
      },
      "source": [
        "### Inference Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pgtVy-9wJURv",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ljll9WCVJUR1"
      },
      "source": [
        "### Decode sample sequeces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HCPV7r8FJUR2",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN0RWDjAwUa_",
        "colab_type": "text"
      },
      "source": [
        "# Evalute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MDwBTM3jJUR4"
      },
      "source": [
        "### Evaluation on Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Te1G_vZXJUR5",
        "colab": {}
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "krcXHYODJUR9",
        "outputId": "a8c9f84f-c90b-476a-ab0f-79c2256a93dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Tamil Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Tamil Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: beware of the dog\n",
            "Actual Tamil Translation:  நாய் ஜாக்கிரதை \n",
            "Predicted Tamil Translation:  நாய் ஜாக்கிரதை \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kmZbLg2yJUST",
        "outputId": "586fe365-e9b6-4524-b638-cb3e554cc3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Tamil Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Tamil Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: im not sure how to answer this\n",
            "Actual Tamil Translation:  எப்படி பதில் சொல்வது என்பதில் நான் உறுதியாக இல்லை \n",
            "Predicted Tamil Translation:  எப்படி பதில் சொல்வது என்பதில் நான் உறுதியாக இல்லை \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DoGA-re5JUUo"
      },
      "source": [
        "### Evaluation on Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q27-EtMIJUUp",
        "colab": {}
      },
      "source": [
        "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VJBVo98OJUUq",
        "outputId": "4c995b1a-7eb4-43a3-8bec-f0a927b6a49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(val_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_test[k:k+1].values[0])\n",
        "print('Actual Tamil Translation:', y_test[k:k+1].values[0][6:-4])\n",
        "print('Predicted Tamil Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: be kind to old people\n",
            "Actual Tamil Translation:  வயோதிகர்களிடம் அன்பாக இரு \n",
            "Predicted Tamil Translation:  வயோதிகர்களிடம் அன்பாக இரு \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}